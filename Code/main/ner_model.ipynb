{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c67f780",
   "metadata": {},
   "source": [
    "# BERT Named Entity Recognition untuk Putusan Pengadilan\n",
    "\n",
    "Notebook ini mengimplementasikan model BERT untuk Named Entity Recognition (NER) pada dokumen putusan pengadilan Indonesia.\n",
    "\n",
    "## Dataset:\n",
    "\n",
    "- **HasilAnotasiPutusanBERT.txt**: Data anotasi dalam format tab-separated untuk BERT training\n",
    "\n",
    "## Entitas Legal yang Dikenali:\n",
    "\n",
    "- **B_DEFN/I_DEFN**: Nama Terdakwa\n",
    "- **B_PROS/I_PROS**: Penuntut Umum\n",
    "- **B_JUDG/I_JUDG**: Hakim Anggota\n",
    "- **B_JUDP/I_JUDP**: Hakim Ketua\n",
    "- **B_VERN/I_VERN**: Nomor Putusan\n",
    "- **B_TIMV/I_TIMV**: Tanggal Putusan\n",
    "- **B_ARTV/I_ARTV**: Pasal KUHP\n",
    "- **B_CRIA/I_CRIA**: Dakwaan/Tuntutan Pidana\n",
    "- **B_PENA/I_PENA**: Tuntutan Hukuman\n",
    "- **B_PUNI/I_PUNI**: Putusan Hukuman\n",
    "- **B_REGI/I_REGI**: Panitera\n",
    "\n",
    "## Model: IndoBERT Base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b339cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\SEMESTER 6\\TEXT MINING\\Uas\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "‚úÖ Libraries imported successfully!\n",
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import libraries untuk BERT NER\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf9fd43",
   "metadata": {},
   "source": [
    "## 1. Load and Analyze BERT Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "879f656f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Total sentences/documents: 235\n",
      "üìù Sample sentence:\n",
      "   Tokens: ['PUTUSAN', 'Nomor', '192/Pid.', 'B/2019/PN', 'Bkl', 'DEMI', 'KEADILAN', 'BERDASARKAN', 'KETUHANAN', 'YANG']...\n",
      "   Labels: ['O', 'O', 'B_VERN', 'I_VERN', 'I_VERN', 'O', 'O', 'O', 'O', 'O']...\n"
     ]
    }
   ],
   "source": [
    "def load_bert_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data dari format tab-separated BERT training data\n",
    "    Format: token\\tlabel\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    current_tokens = []\n",
    "    current_labels = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Skip comments dan doc markers\n",
    "            if line.startswith('#') or line.startswith('-DOCSTART-'):\n",
    "                continue\n",
    "            \n",
    "            # Empty line menandakan akhir sentence\n",
    "            elif not line:\n",
    "                if current_tokens:\n",
    "                    sentences.append((current_tokens, current_labels))\n",
    "                    current_tokens = []\n",
    "                    current_labels = []\n",
    "            \n",
    "            else:\n",
    "                # Parse token dan label\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) >= 2:\n",
    "                    token = parts[0].strip()\n",
    "                    label = parts[1].strip()\n",
    "                    current_tokens.append(token)\n",
    "                    current_labels.append(label)\n",
    "    \n",
    "    # Add last sentence if exists\n",
    "    if current_tokens:\n",
    "        sentences.append((current_tokens, current_labels))\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# Load dataset\n",
    "data_path = '../../Datasets/ANOTASI/HasilAnotasiPutusanBERT.txt'\n",
    "sentences = load_bert_data(data_path)\n",
    "\n",
    "print(f\"üìä Total sentences/documents: {len(sentences):,}\")\n",
    "print(f\"üìù Sample sentence:\")\n",
    "print(f\"   Tokens: {sentences[0][0][:10]}...\")\n",
    "print(f\"   Labels: {sentences[0][1][:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854f6d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Dataset Statistics:\n",
      "   Total tokens: 1,513,881\n",
      "   Unique labels: 23\n",
      "   Average sentence length: 6442.0 tokens\n",
      "   Max sentence length: 26277 tokens\n",
      "\n",
      "üè∑Ô∏è Label Distribution:\n",
      "   O: 1,482,761 (97.94%)\n",
      "   I_DEFN: 7,521 (0.50%)\n",
      "   I_ARTV: 3,114 (0.21%)\n",
      "   I_CRIA: 2,745 (0.18%)\n",
      "   I_JUDG: 2,721 (0.18%)\n",
      "   B_DEFN: 2,711 (0.18%)\n",
      "   I_JUDP: 1,932 (0.13%)\n",
      "   I_PENA: 1,660 (0.11%)\n",
      "   I_VERN: 1,622 (0.11%)\n",
      "   I_REGI: 1,145 (0.08%)\n",
      "   I_PROS: 1,056 (0.07%)\n",
      "   I_PUNI: 726 (0.05%)\n",
      "   B_ARTV: 668 (0.04%)\n",
      "   B_VERN: 666 (0.04%)\n",
      "   I_TIMV: 570 (0.04%)\n",
      "   B_JUDG: 437 (0.03%)\n",
      "   B_PUNI: 356 (0.02%)\n",
      "   B_CRIA: 355 (0.02%)\n",
      "   B_REGI: 282 (0.02%)\n",
      "   B_JUDP: 270 (0.02%)\n",
      "   B_PROS: 234 (0.02%)\n",
      "   B_TIMV: 171 (0.01%)\n",
      "   B_PENA: 158 (0.01%)\n",
      "\n",
      "üéØ Entity ratio: 2.06%\n"
     ]
    }
   ],
   "source": [
    "# Analisis dataset\n",
    "all_tokens = []\n",
    "all_labels = []\n",
    "sent_lengths = []\n",
    "\n",
    "for tokens, labels in sentences:\n",
    "    all_tokens.extend(tokens)\n",
    "    all_labels.extend(labels)\n",
    "    sent_lengths.append(len(tokens))\n",
    "\n",
    "# Label distribution\n",
    "label_counts = Counter(all_labels)\n",
    "unique_labels = sorted(list(set(all_labels)))\n",
    "\n",
    "print(\"üìà Dataset Statistics:\")\n",
    "print(f\"   Total tokens: {len(all_tokens):,}\")\n",
    "print(f\"   Unique labels: {len(unique_labels)}\")\n",
    "print(f\"   Average sentence length: {np.mean(sent_lengths):.1f} tokens\")\n",
    "print(f\"   Max sentence length: {max(sent_lengths)} tokens\")\n",
    "\n",
    "print(\"\\nüè∑Ô∏è Label Distribution:\")\n",
    "for label, count in label_counts.most_common():\n",
    "    percentage = (count / len(all_labels)) * 100\n",
    "    print(f\"   {label}: {count:,} ({percentage:.2f}%)\")\n",
    "\n",
    "print(f\"\\nüéØ Entity ratio: {((len(all_labels) - label_counts['O']) / len(all_labels) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cce190",
   "metadata": {},
   "source": [
    "## 2. Setup BERT Model dan Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e64d0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3d5bf8b2b444ba9cd1f88229100095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117aa59deefc4afdbc52283075b14812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e126de538448dcafb0d694469fad07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Model: archi-ai/Indo-LegalBERT\n",
      "üè∑Ô∏è Number of labels: 23\n",
      "üìù Labels: ['B_ARTV', 'B_CRIA', 'B_DEFN', 'B_JUDG', 'B_JUDP', 'B_PENA', 'B_PROS', 'B_PUNI', 'B_REGI', 'B_TIMV', 'B_VERN', 'I_ARTV', 'I_CRIA', 'I_DEFN', 'I_JUDG', 'I_JUDP', 'I_PENA', 'I_PROS', 'I_PUNI', 'I_REGI', 'I_TIMV', 'I_VERN', 'O']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e9f23da4ca4005bd13fc397d932313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb31d45e8714a758d99458b28ccc14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at archi-ai/Indo-LegalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded and moved to cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup BERT model dan tokenizer\n",
    "model_name = \"archi-ai/Indo-LegalBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Create label mappings\n",
    "label_to_id = {label: i for i, label in enumerate(unique_labels)}\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "num_labels = len(unique_labels)\n",
    "\n",
    "print(f\"ü§ñ Model: {model_name}\")\n",
    "print(f\"üè∑Ô∏è Number of labels: {num_labels}\")\n",
    "print(f\"üìù Labels: {unique_labels}\")\n",
    "\n",
    "# Initialize model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "print(f\"‚úÖ Model loaded and moved to {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ba3070",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing untuk BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04351da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenization function defined\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples, tokenizer, label_to_id, max_length=512):\n",
    "    \"\"\"\n",
    "    Tokenize text dan align labels dengan subword tokens\n",
    "    \"\"\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        \n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                # Special token\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # First subword of word\n",
    "                label_ids.append(label_to_id[label[word_idx]])\n",
    "            else:\n",
    "                # Subsequent subwords - use -100 to ignore in loss\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        \n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = torch.tensor(labels)\n",
    "    return tokenized_inputs\n",
    "\n",
    "print(\"‚úÖ Tokenization function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "417554db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NER Dataset class defined\n"
     ]
    }
   ],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, sentences, tokenizer, label_to_id, max_length=512):\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_to_id = label_to_id\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens, labels = self.sentences[idx]\n",
    "        \n",
    "        # Tokenize\n",
    "        encoding = self.tokenizer(\n",
    "            tokens,\n",
    "            truncation=True,\n",
    "            is_split_into_words=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Align labels\n",
    "        word_ids = encoding.word_ids()\n",
    "        aligned_labels = []\n",
    "        previous_word_idx = None\n",
    "        \n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                aligned_labels.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                aligned_labels.append(self.label_to_id[labels[word_idx]])\n",
    "            else:\n",
    "                aligned_labels.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(aligned_labels, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ NER Dataset class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783f5b82",
   "metadata": {},
   "source": [
    "## 4. Split Data untuk Training, Validation, dan Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b988ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Data Split:\n",
      "   Training: 164 sentences\n",
      "   Validation: 35 sentences\n",
      "   Testing: 36 sentences\n",
      "‚úÖ Datasets created successfully\n"
     ]
    }
   ],
   "source": [
    "# Split data: 70% train, 15% validation, 15% test\n",
    "train_sentences, temp_sentences = train_test_split(\n",
    "    sentences, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "val_sentences, test_sentences = train_test_split(\n",
    "    temp_sentences, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üìä Data Split:\")\n",
    "print(f\"   Training: {len(train_sentences):,} sentences\")\n",
    "print(f\"   Validation: {len(val_sentences):,} sentences\")\n",
    "print(f\"   Testing: {len(test_sentences):,} sentences\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = NERDataset(train_sentences, tokenizer, label_to_id)\n",
    "val_dataset = NERDataset(val_sentences, tokenizer, label_to_id)\n",
    "test_dataset = NERDataset(test_sentences, tokenizer, label_to_id)\n",
    "\n",
    "print(f\"‚úÖ Datasets created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c01f28",
   "metadata": {},
   "source": [
    "## 5. Setup Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c208292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training configuration ready\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute metrics untuk evaluasi\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [id_to_label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id_to_label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    # Flatten for sklearn metrics\n",
    "    flat_true_labels = [label for sublist in true_labels for label in sublist]\n",
    "    flat_predictions = [pred for sublist in true_predictions for pred in sublist]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(flat_true_labels, flat_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        flat_true_labels, flat_predictions, average='weighted', zero_division=0\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./legal-ner-model',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    "    report_to=None,  # Disable wandb\n",
    "    dataloader_pin_memory=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training configuration ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7b4b66",
   "metadata": {},
   "source": [
    "## 6. Train BERT Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "160aa768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting BERT training...\n",
      "   Model: archi-ai/Indo-LegalBERT\n",
      "   Training samples: 164\n",
      "   Validation samples: 35\n",
      "   Epochs: 3\n",
      "   Batch size: 8\n",
      "   Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 42:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting BERT training...\")\n",
    "print(f\"   Model: {model_name}\")\n",
    "print(f\"   Training samples: {len(train_dataset):,}\")\n",
    "print(f\"   Validation samples: {len(val_dataset):,}\")\n",
    "print(f\"   Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"   Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"   Device: {device}\")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "print(\"‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c2d83",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f684109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating on test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Test Results:\n",
      "   Loss: 0.3590\n",
      "   Accuracy: 0.9121\n",
      "   F1: 0.8763\n",
      "   Precision: 0.8561\n",
      "   Recall: 0.9121\n",
      "   Runtime: 71.1608\n",
      "   Samples_Per_Second: 0.5060\n",
      "   Steps_Per_Second: 0.0700\n",
      "\n",
      "üìã Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B_ARTV     0.0000    0.0000    0.0000        11\n",
      "      B_CRIA     0.0000    0.0000    0.0000        34\n",
      "      B_DEFN     0.0000    0.0000    0.0000        87\n",
      "      B_PENA     0.0000    0.0000    0.0000        18\n",
      "      B_PUNI     0.0000    0.0000    0.0000        10\n",
      "      B_VERN     0.0000    0.0000    0.0000        77\n",
      "      I_ARTV     0.0000    0.0000    0.0000        45\n",
      "      I_CRIA     0.0000    0.0000    0.0000       315\n",
      "      I_DEFN     0.7478    0.3007    0.4289       286\n",
      "      I_PENA     0.0000    0.0000    0.0000       156\n",
      "      I_PUNI     0.0000    0.0000    0.0000        20\n",
      "      I_VERN     0.7500    0.0833    0.1500       216\n",
      "           O     0.9138    0.9975    0.9538     12404\n",
      "\n",
      "    accuracy                         0.9121     13679\n",
      "   macro avg     0.1855    0.1063    0.1179     13679\n",
      "weighted avg     0.8561    0.9121    0.8763     13679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"üìä Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "\n",
    "print(\"\\nüéØ Test Results:\")\n",
    "for key, value in test_results.items():\n",
    "    if key.startswith('eval_'):\n",
    "        metric_name = key.replace('eval_', '').title()\n",
    "        print(f\"   {metric_name}: {value:.4f}\")\n",
    "\n",
    "# Detailed predictions for analysis\n",
    "predictions = trainer.predict(test_dataset)\n",
    "test_predictions = np.argmax(predictions.predictions, axis=2)\n",
    "\n",
    "# Convert to readable format\n",
    "test_true_labels = []\n",
    "test_pred_labels = []\n",
    "\n",
    "for i in range(len(test_predictions)):\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    for j in range(len(test_predictions[i])):\n",
    "        if predictions.label_ids[i][j] != -100:\n",
    "            true_labels.append(id_to_label[predictions.label_ids[i][j]])\n",
    "            pred_labels.append(id_to_label[test_predictions[i][j]])\n",
    "    \n",
    "    test_true_labels.extend(true_labels)\n",
    "    test_pred_labels.extend(pred_labels)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nüìã Detailed Classification Report:\")\n",
    "print(classification_report(test_true_labels, test_pred_labels, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49cc421",
   "metadata": {},
   "source": [
    "## 8. Test Predictions on New Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18f5a879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing prediction on sample text:\n",
      "Text: Terdakwa AHMAD BIN SITI berusia 25 tahun terbukti melanggar pasal 362 KUHP dan dijatuhi hukuman penjara 2 tahun oleh Hakim Ketua Dr. BUDI SANTOSO dengan Nomor Putusan 123/Pid.B/2023/PN.Jkt.Sel\n",
      "\n",
      "üìù Prediction Results:\n",
      "   Terdakwa ‚Üí -\n",
      "   AHMAD ‚Üí -\n",
      "   BIN ‚Üí I_DEFN\n",
      "   SITI ‚Üí -\n",
      "   berusia ‚Üí -\n",
      "   25 ‚Üí -\n",
      "   tahun ‚Üí -\n",
      "   terbukti ‚Üí -\n",
      "   melanggar ‚Üí -\n",
      "   pasal ‚Üí -\n",
      "   362 ‚Üí -\n",
      "   KUHP ‚Üí -\n",
      "   dan ‚Üí -\n",
      "   dijatuhi ‚Üí -\n",
      "   hukuman ‚Üí -\n",
      "   penjara ‚Üí -\n",
      "   2 ‚Üí -\n",
      "   tahun ‚Üí -\n",
      "   oleh ‚Üí -\n",
      "   Hakim ‚Üí -\n",
      "   Ketua ‚Üí -\n",
      "   Dr. ‚Üí -\n",
      "   BUDI ‚Üí -\n",
      "   SANTOSO ‚Üí -\n",
      "   dengan ‚Üí -\n",
      "   Nomor ‚Üí -\n",
      "   Putusan ‚Üí -\n",
      "   123/Pid.B/2023/PN.Jkt.Sel ‚Üí -\n"
     ]
    }
   ],
   "source": [
    "def predict_entities(text, model, tokenizer, id_to_label, device):\n",
    "    \"\"\"\n",
    "    Predict entities in new text\n",
    "    \"\"\"\n",
    "    # Tokenize input\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Encode\n",
    "    encoding = tokenizer(\n",
    "        tokens,\n",
    "        is_split_into_words=True,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "    \n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "        predictions = torch.argmax(outputs.logits, dim=2)\n",
    "    \n",
    "    # Convert predictions to labels\n",
    "    # Manually track word IDs based on tokens\n",
    "    predicted_labels = []\n",
    "    token_subwords = []\n",
    "    \n",
    "    # Get subword lengths for each token\n",
    "    for i, token in enumerate(tokens):\n",
    "        # Tokenize each token to see how many subwords it gets split into\n",
    "        subwords = tokenizer.tokenize(token)\n",
    "        token_subwords.append(len(subwords))\n",
    "    \n",
    "    # Map predictions back to original tokens\n",
    "    idx = 1  # Start after [CLS] token\n",
    "    for i, token in enumerate(tokens):\n",
    "        # Get the first subword prediction for this token\n",
    "        if idx < len(predictions[0]):\n",
    "            label_id = predictions[0][idx].item()\n",
    "            predicted_labels.append(id_to_label[label_id])\n",
    "        else:\n",
    "            # Fallback if we somehow exceed the predictions length\n",
    "            predicted_labels.append('O')\n",
    "        \n",
    "        # Skip ahead by the number of subwords for this token\n",
    "        idx += token_subwords[i]\n",
    "    \n",
    "    # Combine tokens with predictions\n",
    "    results = []\n",
    "    for token, label in zip(tokens, predicted_labels):\n",
    "        results.append((token, label))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test dengan contoh teks putusan\n",
    "sample_text = \"Terdakwa AHMAD BIN SITI berusia 25 tahun terbukti melanggar pasal 362 KUHP dan dijatuhi hukuman penjara 2 tahun oleh Hakim Ketua Dr. BUDI SANTOSO dengan Nomor Putusan 123/Pid.B/2023/PN.Jkt.Sel\"\n",
    "\n",
    "print(\"üîç Testing prediction on sample text:\")\n",
    "print(f\"Text: {sample_text}\\n\")\n",
    "\n",
    "prediction_results = predict_entities(sample_text, model, tokenizer, id_to_label, device)\n",
    "\n",
    "print(\"üìù Prediction Results:\")\n",
    "for token, label in prediction_results:\n",
    "    if label != 'O':\n",
    "        print(f\"   {token} ‚Üí {label}\")\n",
    "    else:\n",
    "        print(f\"   {token} ‚Üí -\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d9b21",
   "metadata": {},
   "source": [
    "## 9. Save Trained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b42430b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved to: ./legal-ner-bert-model\n",
      "\n",
      "============================================================\n",
      "           üéâ BERT NER MODEL TRAINING COMPLETED\n",
      "============================================================\n",
      "üìä Dataset: 235 sentences from legal documents\n",
      "üè∑Ô∏è Entities: 31,120 legal entities\n",
      "ü§ñ Model: archi-ai/Indo-LegalBERT\n",
      "üéØ Test Accuracy: 0.9121\n",
      "üìà Test F1-Score: 0.8763\n",
      "üíæ Model Location: ./legal-ner-bert-model\n",
      "\n",
      "üöÄ Model ready for legal document entity extraction!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "model_save_path = \"./legal-ner-bert-model\"\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "# Save label mappings\n",
    "import json\n",
    "label_mappings = {\n",
    "    'label_to_id': label_to_id,\n",
    "    'id_to_label': id_to_label,\n",
    "    'unique_labels': unique_labels\n",
    "}\n",
    "\n",
    "with open(os.path.join(model_save_path, 'label_mappings.json'), 'w') as f:\n",
    "    json.dump(label_mappings, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {model_save_path}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"           üéâ BERT NER MODEL TRAINING COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìä Dataset: {len(sentences):,} sentences from legal documents\")\n",
    "print(f\"üè∑Ô∏è Entities: {len([l for l in all_labels if l != 'O']):,} legal entities\")\n",
    "print(f\"ü§ñ Model: {model_name}\")\n",
    "print(f\"üéØ Test Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"üìà Test F1-Score: {test_results['eval_f1']:.4f}\")\n",
    "print(f\"üíæ Model Location: {model_save_path}\")\n",
    "print(\"\\nüöÄ Model ready for legal document entity extraction!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
